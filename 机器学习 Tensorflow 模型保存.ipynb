{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 机器学习 Tensorflow 模型保存\n",
    "\n",
    "### 一、实例化模型保存对象\n",
    ">saver=tf.train.Saver(max_to_keep=1)<br>\n",
    "\n",
    "**参数：**<br>\n",
    ">max_to_keep: 表明保存的最大checkpoint 文件数。当一个新文件创建的时候，旧文件就会被删掉。如果值为None或0，表示保存所有的checkpoint 文件。默认值为5（也就是说，保存最近的5个checkpoint 文件）。<br>\n",
    "keep_checkpoint_every_n_hour: 除了保存最近的max_to_keep checkpoint 文件，你还可能想每训练N小时保存一个checkpoint 文件。这将是非常有用的，如果你想分析一个模型在很长的一段训练时间内是怎么改变的。例如，设置 keep_checkpoint_every_n_hour=2 确保没训练2个小时保存一个checkpoint 文件。默认值10000小时无法看到特征。<br>\n",
    "\n",
    "### 二、保存训练过程中的或者训练好的模型图及权重参数<br>\n",
    "创建完saver对象后，就可以保存训练好的模型了<br>\n",
    ">saver.save(sess=sess,save_path=model_save_path,global_step=step)<br>\n",
    "\n",
    "**参数:**<br>\n",
    ">sess=sess　　　　　　　　#　会话名字；<br>\n",
    "save_path=model_save_path　　　　　　#　设定权重参数保存的路径和文件名；<br>\n",
    "global_step=step　　　　　　　　　#　将训练的次数作为后缀加入到模型名字中。<br>\n",
    "\n",
    "　　一次 saver.save() 后可以在文件夹中看到新增的四个文件，实际上每调用一次保存操作会创建后3个数据文件并创建一个检查点（checkpoint）文件。简单理解就是权重等参数被保存到 .ckpt.data 文件中，以字典的形式；.ckpt-index，应该是内部需要的某种索引来正确映射前两个文件；图和元数据被保存到 .ckpt.meta 文件中，可以使用tf.train.import_meta_graph 加载。<br>\n",
    "### 三、重载模型的图及权重参数<br>\n",
    "重载模型的参数，继续训练或用于测试数据。<br>\n",
    ">saver.restore(sess=sess, save_path=model_save_path)<br>\n",
    "\n",
    "**参数:**<br>\n",
    ">sess=sess　　　　　　#　会话名字；<br>\n",
    "save_path=model_save_path　　　　　#　权重参数的保存的路径和文件名。<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

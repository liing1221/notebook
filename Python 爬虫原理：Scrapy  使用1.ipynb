{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapy 使用1\n",
    "　　参考：[scrapy分布式Spider源码分析及实现过程](https://blog.csdn.net/weixin_41624982/article/details/88561874)<br>\n",
    "　　　　　[scrapy-redis（五）：scrapy中信号工作的原理](https://blog.csdn.net/hjhmpl123/article/details/53465176?utm_source=blogxgwz4)<br>\n",
    "　　　　　[scrapy的使用](https://www.jianshu.com/p/47558e1a9eef)、[scrapy](https://www.jianshu.com/p/7dee0837b3d2)<br>\n",
    "　　　　　[scrapy文档](https://scrapy-chs.readthedocs.io/zh_CN/0.24/topics/item-pipeline.html)<br>\n",
    "　　　　　[scrapy_redis代码注解](https://github.com/lymlhhj123/scrapy_redis_spider)<br>\n",
    "　　　　　[爬虫大V](https://blog.csdn.net/sinat_35360663/category_7270146.html)<br>\n",
    "　　　　　[scrapy-redis分布式爬虫如何在start_urls中添加参数](https://blog.csdn.net/zwq912318834/article/details/79720742)<br>\n",
    "　　　　　[RedisSpider的调度队列实现过程及其源码](https://blog.csdn.net/weixin_41624982/article/details/88411549)<br>\n",
    "　　　　　[Scrapy Redis源码 spider分析](https://blog.csdn.net/haipengdai/article/details/48573201)<br>\n",
    "　　　　　[scrapy-redis(调度器Scheduler源码分析)](https://www.cnblogs.com/yunxintryyoubest/p/9954481.html)<br>\n",
    "　　　　　[第三百五十八节，Python分布式爬虫打造搜索引擎Scrapy精讲—将bloomfilter(布隆过滤器)集成到scrapy-redis中](https://blog.csdn.net/weixin_34256074/article/details/85935479)<br>\n",
    "　　　　　[请教scrapy DOWNLOAD_FAIL_ON_DATALOSS 作用](https://segmentfault.com/q/1010000011498289/a-1020000015387850)<br>\n",
    "　　　　　[scrapy信号 signals 笔记](https://blog.csdn.net/qq_41020281/article/details/82779919)<br>\n",
    "　　　　　[URL去重的几种方法](blog.csdn.net/hellozhxy/article/details/80942581)<br>\n",
    "　　　　　[scrapy去重队列优化](https://blog.csdn.net/weixin_37923128/article/details/80992561)<br>\n",
    "　　　　　[解决 Scrapy-Redis 空跑问题，链接跑完后自动关闭爬虫](http://www.mamicode.com/info-detail-2225397.html)<br>\n",
    "　　　　　[scrapy信号扩展](https://www.cnblogs.com/c491873412/p/7845635.html)<br>\n",
    "　　　　　[Python爬虫：Scrapy的Crawler对象及扩展Extensions和信号Signals](https://blog.csdn.net/mouday/article/details/84024767)<br>\n",
    "　　　　　[scrapy-redis分布式爬虫如何在start_urls中添加参数](https://blog.csdn.net/zwq912318834/article/details/79720742)<br>\n",
    "　　　　　[崔庆才的腾讯云材料_Scrapy框架的使用之Item Pipeline的用法](https://cloud.tencent.com/developer/article/1151838)<br>\n",
    "　　　　　[数据采集: scrapy-redis源码分析(一) ](https://www.cnblogs.com/zlone/p/11079481.html)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

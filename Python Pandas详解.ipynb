{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas详解\n",
    "　　参考：[Pandas官方文档](https://pandas.pydata.org/pandas-docs/stable/)  \n",
    "　　　　　[Pandas中文社区](https://www.pypandas.cn/https://www.pypandas.cn/)   \n",
    "　　　　　[Pandas 科学计算](https://www.osgeo.cn/python-tutorial/pd1.html) \n",
    "　　　　　[22个案例详解 Pandas 数据分析/预处理时的实用技巧，超简单](https://mp.weixin.qq.com/s/3O1H_u4PAHaNWEzIDhEY3g)   \n",
    "　　　　　[Pandas 重复数据处理大全](https://mp.weixin.qq.com/s/dmfUBmmIRoJ1XhfK7zElyA)  \n",
    "　　　　　[第3次翻译了 Pandas 官方文档，叒写了这一份R万字肝货操作！](https://mp.weixin.qq.com/s/dmfUBmmIRoJ1XhfK7zElyA)   \n",
    "　　　　　[10000字的Pandas核心操作知识大全！](https://mp.weixin.qq.com/s/vQdmKdrOJ49z2M6SQwmbEQ)   \n",
    "　　　　　[Pandas缺失数据处理大全](https://mp.weixin.qq.com/s/Ly7P1zhAJSdNu8TU5Xc2uA)    \n",
    "　　　　　[pandas 文本处理大全（附代码）](https://mp.weixin.qq.com/s/5_A5gQPYFAJkbTrjIq1WzQ)    \n",
    "　　　　　[SettingWithCopyWarning](https://blog.csdn.net/Fwuyi/article/details/123519659)   \n",
    "　　　　　[Pandas的使用](https://blog.csdn.net/weixin_39621075/article/details/111196755)   \n",
    "　　　　　[用pandas进行数据分析实战](https://blog.csdn.net/m0_59963538/article/details/119105599)   \n",
    "　　　　　[pandas给dataframe赋值—修改特定值](https://blog.csdn.net/weixin_45736572/article/details/122596045)     \n",
    "　　　　　[Pandas的DataFrame的加减乘除运算 （18）](https://blog.csdn.net/qq_36622490/article/details/103118072)   \n",
    "　　　　　[]()    \n",
    "　　　　　[]()    \n",
    "　　　　　[]()    \n",
    "　　　　　[]()    \n",
    "　　　　　[]()    \n",
    "　　　　　[]()    \n",
    "　　　　　[]()    \n",
    "　　　　　[]()    \n",
    "　　　　　[]()    \n",
    "## 一、Pandas快速入门\n",
    "1.1　Pandas简介\n",
    "1.1.1　Pandas的使用人群\n",
    "1.1.2　Pandas的基本功能\n",
    "1.1.3　Pandas的学习方法\n",
    "\n",
    "1.2　环境搭建及安装\n",
    "1.2.1　Python环境安装\n",
    "1.2.2　Anaconda简介\n",
    "1.2.3　安装miniconda\n",
    "1.2.4　多Python版本环境\n",
    "1.2.5　安装编辑器\n",
    "1.2.6　Jupyter Notebook\n",
    "1.2.7　用pip安装三方库\n",
    "1.2.8　安装Jupyter Notebook\n",
    "1.2.9　启动Jupyter Notebook\n",
    "1.2.10　使用Jupyter Notebook\n",
    "1.2.11　安装Pandas\n",
    "\n",
    "1.3　Pandas快速入门\n",
    "1.3.1　安装导入\n",
    "1.3.2  Pandas基本概念\n",
    "索引：index\n",
    "轴：axis   0 横向 1 纵向\n",
    "行 row  列 column\n",
    "标签 label: 索引的值\n",
    "\n",
    "#### 1.3.3、数据类型\n",
    "\n",
    "|类型|Python原生类型|NumPy类型|用途|\n",
    "|:---|:---|:---|:---|\n",
    "|object|str or mixed| string_、unicode_、mixed types|文本或者混合数字|\n",
    "|int64|int|int_、int8、int16、int32、int64、uint8、uint16、uint32、uint64|整形数字|\n",
    "|float64|float|float_、float16、float32、float64|浮点数字|\n",
    "|bool|bool|bool_|True/False 布尔型|\n",
    "|datetime64\\[ns\\]|nan|datetime64\\[ns\\]|日期时间|\n",
    "|timedelta\\[ns\\]|nan|nan|两个时间之间的距离，时间差|\n",
    "|category|nan|nan|类别数据：有限文本值，枚举|\n",
    "\n",
    "查看数据类型  \n",
    "df.dtypes        # 各字段的数据类型  \n",
    "df.team.dtype      # 某个字段的数据类型，如：team  \n",
    "s.dtype     # Series数据的类型  \n",
    "df.dtypes.value_counts()     # 各类型有多少个字段  \n",
    "  \n",
    "修改数据类型  \n",
    "df.astype('int32')    # 所有数据转换为int32类型  \n",
    "df.astype({'col1': 'int32'})    # 指定col1转换为指定类型：int32  \n",
    "df.convert_dtypes()   # 推荐！新的方法，支持string类型:自动推断，智能转化为合适的数据类型   \n",
    "\n",
    "df.infer_object()  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1.3.2　准备数据集\n",
    "1.3.3　读取数据\n",
    "1.3.4　查看数据\n",
    "1.3.5　验证数据\n",
    "\n",
    "#### 1.3.6　索引\n",
    "\n",
    "+ 行索引是数据的索引，列索引指向的是一个Series\n",
    "+ DataFrame 的索引也是column, 列形成的Series的索引 \n",
    "+ 建立索引让数据更加直观明确，更加方便处理\n",
    "+ 索引允许重复\n",
    "\n",
    "查看索引  \n",
    "df.index    # 查看行索引  \n",
    "df.columns     # 查看列索引  \n",
    "\n",
    "创建索引\n",
    "url = 'https://www.gairuo.com/file/data/dataset/team.xlsx'  \n",
    "df = pd.read_excel(data, index_col='name')     # 设置索引为'name'列  \n",
    "s = pd.Series([1, 2, 3, 4, 5])  \n",
    "df.set_index(s)         # 指定一个索引s  \n",
    "\n",
    "df.reset_index()     # 重置索引，原有的索引列插入到新的df中，列名为index     \n",
    "df.reset_index(drop=True)    # 重置索引，并使原有的索引列不插入到新的df中\n",
    "df.rename(columns={\"A\": 'a', \"B\":'b'})    # 一一对应修改列索引  \n",
    "df.set_axis(\\['a', 'b', 'c'\\], axis='index')       # 修改索引  \n",
    "df.rename_axis('info', axis='columns')       # 修改行索引名  \n",
    "\n",
    "#### 1.3.7 查看数据结构信息\n",
    "df.head(10)   # 查看前10条数据(查看头部数据)  \n",
    "df.tail()   # 查看后5调数据（用法同head,查看尾部数据）  \n",
    "df.tail(10)   #查看后10调数据  \n",
    "df.sample()    # 随机查看一条数据: 用于从dataframe或者series中，随机取样。    \n",
    "df.sample(3)   # 随机查看3调数据  \n",
    "df.sample(10, ignore_index=True)   # 随机后重置索引  \n",
    "df.shape    # 数据形状 （3， 4）  3行 4列  \n",
    "df.info()    # 数据信息  \n",
    "\n",
    "注：查看数据时，由于篇幅原因，显示中部分数据省略，我们可以通过一下方法调整展示的长度与宽度，以显示更多信息\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.width\", 500)\n",
    "\n",
    "\n",
    "\n",
    "df.index    # RangeIndex(start=0, stop=100, step=1)  \n",
    "df.columns   # 列索引  Series 不支持  \n",
    "df.dtypes   # 数据类型  \n",
    "df.axes    # 行列索引内容  \n",
    "\n",
    "df.size    # 3行 4列 的数据总数 ，即：总共多少个数据 3\\*4  \n",
    "df.empty    # False  判断是否空数据  \n",
    "\n",
    "df.to_numpy()    # numpy array(<所有值得列表矩阵>)  \n",
    "df.attrs={\"info\":\"学生成绩表\"}    # 设置元信息，可用与数据基础信息描述  \n",
    "\n",
    "##### 1.3.7.1 pd方法df.sample()\n",
    "　　df.sample()用于从dataframe或者series中，随机取样。   　　\n",
    "　　官方文档:　   \n",
    "```python\n",
    "DataFrame.sample(self: ~ FrameOrSeries, n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)　　　\n",
    "```\n",
    "　　构建实例：\n",
    "```python\n",
    "import pandas as pd \n",
    "df = pd.DataFrame({'name':['zhao','qian','sun','wang'],'mark':[150,122,155,132],'gender':['female','female','male','male']})\n",
    "df\n",
    "\n",
    "\tname\tmark\tgender\n",
    "0\tzhao\t150\t\tfemale\n",
    "1\tqian\t122\t\tfemale\n",
    "2\tsun\t\t155\t\tmale\n",
    "3\twang\t132\t\tmale\n",
    "```\n",
    "　　参数详解:  \n",
    "1、n:int,optional  \n",
    "　　从数据集中随机选取n行数据，不能和frac参数同时使用。如果frac=None，那么n默认为1.  \n",
    "```python\n",
    "\tname\tmark\tgender\n",
    "0\tzhao\t150\t\tfemale\n",
    "1\tqian\t122\t\tfemale\n",
    "2\tsun\t\t155\t\tmale\n",
    "3\twang\t132\t\tmale\n",
    "\n",
    "df.sample(2)\n",
    "\tname\tmark\tgender\n",
    "1\tqian\t122\t\tfemale\n",
    "0\tzhao\t150\t\tfemale\n",
    "```\n",
    "2、frac：float，optional  \n",
    "　　从数据集中选取一定比例的数据，不能和n同时使用。如果frac>1,replace必须为True  \n",
    "```python\n",
    "df.sample(frac=0.75)\n",
    "\n",
    "\tname\tmark\tgender\n",
    "2\tsun\t\t155\t\tmale\n",
    "1\tqian\t122\t\tfemale\n",
    "0\tzhao\t150\t\tfemale\n",
    "```\n",
    "\n",
    "3、replace：bool，default False  \n",
    "　　是否允许重复取样，即一条数据多次选取。默认为否  \n",
    "```python\n",
    "df.sample(3,replace=True)\n",
    "\n",
    "\tname\tmark\tgender\n",
    "0\tzhao\t150\t\tfemale\n",
    "1\tqian\t122\t\tfemale\n",
    "0\tzhao\t150\t\tfemale\n",
    "#里面有重复的数据\n",
    "```\n",
    "\n",
    "4、weight：str or narray-like,optional  \n",
    "　　为每条数据添加权重。默认为None。如果axis = 0，可以直接使用某一列为权重。除非权重的类型为series，否则权重的长度必须和数据集中所用轴方向的（axis=0 or ）一样长。如果权重和大于一，则会归一化为1。  \n",
    "```python\n",
    "\tname\tmark\tgender\n",
    "0\tzhao\t150\t\tfemale\n",
    "1\tqian\t122\t\tfemale\n",
    "2\tsun\t\t155\t\tmale\n",
    "3\twang\t132\t\tmale\n",
    "df.sample(3,replace=True,weights=[1,2,3,4])\n",
    "\n",
    "\tname\tmark\tgender\n",
    "3\twang\t132\t\tmale\n",
    "3\twang\t132\t\tmale\n",
    "3\twang\t132\t\tmale\n",
    "#选取到3行的概率更大了\n",
    "```\n",
    "5、random_state:int or numpy.random.randomstate.optional  \n",
    "　　随机数种子: 指定随机数种子后，每次选取的结果就固定了。  \n",
    "```python\n",
    "df.sample(2,replace=True,random_state=3)\n",
    "\n",
    "\tname\tmark\tgender\n",
    "2\tsun\t\t155\t\tmale\n",
    "0\tzhao\t150\t\tfemale\n",
    "```\n",
    "6、axis  \n",
    "　　选择轴向，0（index）或者1（columns），默认是0  \n",
    "\n",
    "\n",
    "\n",
    "#### 1.3.8 查看数据统计信息\n",
    "df.describe()    # 描述性统计\n",
    "df.mean()      # 返回所有列的均值\n",
    "df.mean(1)     # 返回所有行的均值；下同\n",
    "df.corr()      # 返回列与列之间的相关系数\n",
    "df.count()      # 返回每一列中的非空值的个数\n",
    "df.max()      # 返回每一列的最大值\n",
    "df.min()       # 返回每一列的最小值\n",
    "df.abs()        # 绝对值\n",
    "df.median()      # 返回每一列的中位数\n",
    "df.std()    # 返回每一列的标准差，贝塞尔校正的样本标准偏差\n",
    "df.var()     # 无偏方差\n",
    "df.sem()     # 平均值的标准误差\n",
    "df.sum()     # 求和  参数1  按行求和   参数2  按例求和  \n",
    "df['sum'] = df[['chinese', 'math', 'english']].sum(1) = df['chinese'] + df['math'] + df['english']\n",
    "\n",
    "df.mode()      # 众数\n",
    "df.prod()      # 连乘\n",
    "df.mad()       # 平均绝对偏差\n",
    "df.cumprod()   # 累计连乘，累乘\n",
    "df.cumsum(axis=0)     # 累计连加，累加\n",
    "df.nunique()   # 去重数量，不同值的量\n",
    "df.idxmax()    # 每列最大的值得索引名\n",
    "df.idxmin()    # 每列最小的值得索引名\n",
    "df.cummax()    # 累计最大值\n",
    "df.cummin()    # 累计最小值\n",
    "df.skew()      # 样本偏度（第三阶）\n",
    "df.kurt()      # 样本峰度（第四阶）\n",
    "df.quantile()   # 样本分位数（不同%的值）  参数为分位数列表，如：df['math'].quantile([0.3, 0.4, 0.5])\n",
    "\n",
    "\n",
    "\n",
    "#### 1.3.8 数据计算\n",
    "df.diff()   # 位差  为本行减去前一行  0 行为 NaN\n",
    "df.diff(axis=1)   # 向右一列\n",
    "df.diff(2)\n",
    "df.diff(-1)    # 新行为本行减去后一行  最后一行为 NaN\n",
    "\n",
    "df.shift()    # 整体下移一行，最顶一行为NaN\n",
    "df.shift(3)    # 整体下移3行\n",
    "\n",
    "df.rank()    # 排名，将值变了序号数\n",
    "df.rank(axis=1)  # 横向排名\n",
    "\n",
    "df + 1  \n",
    "df.add()   # 加\n",
    "df.sub()   # 减\n",
    "df.mul()   # 乘\n",
    "df.div()   # 除\n",
    "df.divmod()   # 返回 (a//b, a%b)\n",
    "df.truediv()   # Divide DataFrames (float division)\n",
    "df.floordiv()   # Divide DataFrames (integer division)\n",
    "df.mod()   # 模，除后的余数\n",
    "df.pow()   # 指数幂\n",
    "df.dot(df2)   # 矩阵运算\n",
    "\n",
    "\n",
    "df.all()   # 返回所有列的all()值得Series\n",
    "df.any()   # \n",
    "\n",
    "df.eval('Q2Q3=Q2 + Q3')   # 用表达式计算生成列。仅支持列，不太安全\n",
    "df.eval('Q2Q3=Q2 + Q3', inplace=True)      # 替换生效\n",
    "\n",
    "df.round(2)    #　四舍五入\n",
    "df.round({\"Q1\": 2, \"Q2\":0}     # 指定字段指定保留小数位\n",
    "df.round(-1)    # 保留10位\n",
    "\n",
    "df.nunique()     # 每个列的去重值得数量\n",
    "s.nunique()    # 本列的去重值\n",
    "\n",
    "df.isna()     # 真假监测：值的真假值替换\n",
    "df.notna()     # 与上相反\n",
    "\n",
    "pd.isnull(x)     # 判断null     \n",
    "df.isna()     # 判断nan  或者 import math   math.isnan(x) 判断x是否为nan\n",
    "\n",
    "\n",
    "#### 1.3.9 数据查询\n",
    "df['name']   # 返回本列的Series\n",
    "df.name    # df.my name  有空格无法调用，可以处理加上下划线\n",
    "df.Q1   # df.1Q   即使列名叫1Q也无法使用\n",
    "\n",
    "df.truncate(before=2, after=4)    # 数据截取，去掉索引之前和之后的数据；如：只要索引 2-4\n",
    "df.truncate(before='60', after='66')    \n",
    "df.truncate(before=\"a\", after=\"B\", axis=\"columns\")    # 选取列\n",
    "\n",
    "df.at[4, 'Q1']     # 注意：索引是字符需要加引号\n",
    "df.at['lily', 'Q1']    # \n",
    "df.at[0, 'name']   \n",
    "df.loc[0].at['name']\n",
    "\n",
    "#### 1.3.10 复查数据查询\n",
    "\n",
    "|操作|语法|返回结果|\n",
    "|:---|:---|:---|\n",
    "|选择列|df[col]|Series|\n",
    "|按索引选择行|df.loc[label]|Series|\n",
    "|按数字索引选择行|df.iloc[loc]|Series|\n",
    "|实用切片选择行|df[5:10]|DataFrame|\n",
    "|用表达式筛选行|df[bool_vec]|DataFrame|\n",
    "\n",
    "df.loc[:, ['Q1', 'Q2']]   # 所有行， Q1 和 Q2 两列\n",
    "df.loc[:10, 'Q1'：]   # 0-10行， Q1 后的所有列 \n",
    "\n",
    "df.iloc[:3]\n",
    "df.iloc[:]\n",
    "df.iloc[:, [1, 2, 3]]\n",
    "df.iloc[2:20:3]\n",
    "s.iloc[:3]\n",
    "\n",
    "df[df['Q1']==8]    # Q1 等于 8\n",
    "df[~(df['Q1']==8)]    # 不等于 8\n",
    "df[df.name=='Ben']    # 姓名为 Ben\n",
    "df.loc[df['Q1'] > 90, 'Q1':]   # Q1 > 90, 显示Q1后的所有列\n",
    "df.loc[(df.Q1 > 80) & (df.Q2 < 15)]   # and关系\n",
    "df.loc[(df.Q1 > 90)|(df.Q2 < 90)]   # or 关系\n",
    "df[df.Q1 > df.Q2]\n",
    "\n",
    "通过列位置筛选列\n",
    "df.loc[:, lambda df: df.columns.str.len() == 4]     # 真假组成的序列\n",
    "df.loc[:, lambda df: [i for i in df.columns if 'Q' in i]]   # 列名列表\n",
    "df.iloc[:3, lambda df: df.columns.str.len() == 2]    # 真假组成的序列\n",
    "\n",
    "df.eq()   # 等于相等 ==\n",
    "df.ne()   # 不等于 ！=\n",
    "df.le()   # 小于等于 <=\n",
    "df.lt()   # 小于 <\n",
    "df.ge()   # 大于等于 >=\n",
    "df.gt()   # 大于 >\n",
    "df[df.Q1.ne(89)]   # Q1 不等于8\n",
    "df.loc[df.Q1.gt(90) & df.Q2.lt(90)]    # and 关系  Q1 > 90 Q2 < 90\n",
    "\n",
    "df[df.team.isin(['A', \"B\"])]   # 包含AB两组的\n",
    "df[df.isin({'team':['C', \"D\"], 'Q1':[36, 93]})]   # 复杂查询，其他值为NaN\n",
    "\n",
    "\n",
    "#### 1.3.11　数据筛选\n",
    "　　参考：[pandas实现筛选功能方式](https://blog.csdn.net/weixin_42322206/article/details/123607271)   \n",
    "s.where(s>90, 0)     # 不符合条件的为0\n",
    "np.where(s>80, True, False)\n",
    "s.mask(s > 90, 0)    # 符合条件的为0\n",
    "\n",
    "df.query('Q1 > Q2 > 90')   # 直接写类似sql where 语句\n",
    "df.query('Q1 + Q2 > 180')\n",
    "df.query('Q1==Q2')\n",
    "df.query('(Q1<50) & (Q2>40) and (Q3>90)')\n",
    "\n",
    "df.filter(items=['Q1', 'Q2'])   # 选择两列\n",
    "df.filter(regex='Q', axis=1)   # 列名包含Q的\n",
    "df.filter(regex='e', axis=1)   # 以 e(dollar 符号) 结尾的\n",
    "\n",
    "df.select_dtypes(include=['float64'])   # 选择 float64 类型数据\n",
    "df.select_dtypes(include='bool')  \n",
    "df.select_dtypes(include=['number'])   # 只取数字类型\n",
    "df.select_dtypes(exclude=['int'])    # 排除 int 类型\n",
    "df.select_dtypes(exclude=['datetime64'])\n",
    "df.select_dtypes('number')     # 选择某数据类型的列\n",
    "\n",
    "df[(df.loc[:, ['Q1\", \"Q2']] > 80).all(1)]    # 选取Q1 Q2 成绩全大于80的\n",
    "df[(df.loc[:, ['Q1', 'Q2']] > 80).any(1)]    # 选取Q1 Q2 成绩至少有一个 80 的   \n",
    "\n",
    "数据去重  \n",
    "```python\n",
    "df.drop_duplicates(\n",
    "    subset: Hashable | Sequence[Hashable] | None = None,   # 列标签或标签序列，可选某些列为基准进行去重，默认情况下使用所有列\n",
    "        keep: Literal[\"first\"] | Literal[\"last\"] | Literal[False] = \"first\",   # first是保留第一个，删除后面重复值；last是删除前面，保留最后一个。\n",
    "        inplace: bool = False,\n",
    "        ignore_index: bool = False,\n",
    "    ) -> DataFrame | None\n",
    "```\n",
    "DataFrame.drop_duplicated(self，subset = None，keep ='first')  \n",
    "subset ： 列标签或标签序列，可选仅考虑某些列来标识重复项，默认情况下使用所有列  \n",
    "keep ： {'first'，'last'，False}，默认为'first'  \n",
    "\t\tfirst：将重复项标记True为第一次出现的除外。    \n",
    "\t\tlast：将重复项标记True为最后一次除外。    \n",
    "\t\tFalse：将所有重复项标记为True。  \n",
    "\n",
    "\n",
    "#### 1.3.12　数据排序\n",
    "\n",
    "索引排序    \n",
    "s.sort_index()    # 升序排列  \n",
    "df.sort_index()     # df 也按索引进行排序  \n",
    "df.team.sort_index()      \n",
    "s.sort_index(ascoding=False)    # 降序排列   \n",
    "    \n",
    "数值排序  \n",
    "s.sort_values()   # 升序   \n",
    "s.sort_values(ascoding=False)   # 降序   \n",
    "参数：  \n",
    "by : str or list of str（字符或者字符列表）   \n",
    "ascending : bool or list of bool, default True（是否升序排序，默认升序为True，降序则为False。如果是列表，则需和by指定的列表数量相同，指明每一列的排序方式）  \n",
    "na_position : {‘first’,‘last’}, default ‘last'.（如果指定排序的列中有nan值，可指定nan值放在第一个还是最后一个）   \n",
    "   \n",
    "全降序   \n",
    "df.sort_values(by=['team', 'Q1'], ascoding=False)   \n",
    "对应指定team升 Q1降  \n",
    "df.sort_values(by=['team', 'Q1'], ascoding=[True, False])  \n",
    "   \n",
    "s.nsmallest(3)     # 最小的三个  \n",
    "s.nlargest(3)      # 最大的三个  \n",
    "指定列  \n",
    "df.nlargest(3, 'Q1')  \n",
    "df.nlargest(5, ['Q1', 'Q2'])  \n",
    "df.nsmallest(5, ['Q1', 'Q2'])    \n",
    "\n",
    "\n",
    "#### 1.3. 13 数据的增、删、改、查\n",
    "df.Q1 = [1, 3, 5, 7, 9] * 20     # 修改数据值\n",
    "df.loc[1:3, 'Q1':'Q2'] = 99      # 按范围修改数据为99\n",
    "\n",
    "对索引值进行修改\n",
    "df.rename(columns={\"Q1\": \"a\", \"Q2\": \"b\"})    # 对表头进行修改\n",
    "df.rename(index={0:\"x\", 1:\"y\", 2:\"z\"})     # 对索引进行修改\n",
    "\n",
    "df.replace(0, 5)    # 将数据中所有0 换为5\n",
    "df.fillna(0)    # 空全修改为0\n",
    "\n",
    "df['foo'] = 100   # 增加一列foo,所有值都是100\n",
    "df['foo'] = df.Q1 + df.Q2     # 新列为两列相加\n",
    "df['foo'] = df['Q1'] + df['Q2']    # 同上\n",
    "\n",
    "增加一列并赋值，不满足条件的为NaN\n",
    "df.loc[df.num >= 60, '成绩'] = '合格'\n",
    "df.loc[df.num < 60, '成绩'] = '不合格'\n",
    "\n",
    "df.assign(Q5=[100] * 100)     # 新增加一列Q5\n",
    "df = df.assign(Q5=[100] * 100)   # 赋值生效\n",
    "df.assign(Q6=df.Q2/df.Q1)    # 计算并增加Q6\n",
    "\n",
    "df\\['C1'\\] = df.eval('Q2 + Q3')\n",
    "df.eval('C2 = Q2 + Q3')    # 计算\n",
    "\n",
    "pandas中DataFrame删除对象可能存在几种情况  \n",
    "1、删除具体列  \n",
    "2、删除具体行  \n",
    "3、删除包含某些数值的行或者列  \n",
    "4、删除包含某些字符、文字的行或者列 \n",
    "  \n",
    ">DataFrame.drop(labels=None,axis=0, index=None, columns=None, inplace=False)\n",
    "\n",
    "参数：　　\n",
    "+ labels：要删除的行或列，用列表给出\n",
    "+ axis：默认为0，指要删除的是行，删除列时需指定axis为1\n",
    "+ index ：直接指定要删除的行，删除多行可以使用列表作为参数\n",
    "+ columns：直接指定要删除的列，删除多列可以使用列表作为参数\n",
    "+ inplace: 默认为False，该删除操作不改变原数据；inplace = True时，改变原数据\n",
    "\n",
    "df.pop('Q1')     # 删除一列  \n",
    "df.drop('Q1', axis=1)  \n",
    "\\_s = s.drop('c')     # Series 删除\n",
    "df.drop('b', inplace=True, axis=1)    # 删除一列，inplace=True 删除原数据  df发生变化   \n",
    "\n",
    "s.pop(3)    # 删除一个索引位: 一行  \n",
    "new_df = df.drop('Liver')    # 名称索引  \n",
    "new_df = df.drop(df.index[7])    # 根据行号删除   \n",
    "注意，这个办法其实不是按照行号删除，而是按照索引删除。如果index为3，则会将前4条记录都删除。这个方法支持一个范围，以及用负数表示从末尾删除。  \n",
    "删除某列包含特殊字符的行\n",
    "df[ \\~ df['证券名称'].str.contains('联通') ]    # 如果想取包含某些字符的记录，可以去掉\\~   \n",
    "也可以把想要的列筛选出来赋值给df达到删除的目的\n",
    "df.drop(['B', 'C'], axis=1)    # 删除两列\n",
    "df.drop(columns=['B', 'C'])   # 同上\n",
    "\n",
    "#### 1.3.14 Pandas数据迭代遍历\n",
    "按行\n",
    "for index, row in df.iterrows():\n",
    "    print(index, row['name'], row.team, row.Q1)\n",
    "    \n",
    "按行，命名元组\n",
    "for row in df.itertuples():\n",
    "    print(row)\n",
    "    # Pandas(Index=0, name='Liver', team='E', Q1=89, Q2=21, Q3=24, Q4=64)\n",
    "    \n",
    "按列\n",
    "for label, ser in df.loc[1].items():\n",
    "    print(label, ser)\n",
    "\n",
    "#### 1.3.15 Pandas函数应用\n",
    "df['col2'] = df['col1'].map(lambda x: x\\*\\*2)   # 在Pandas中，DataFrame的一列就是一个Series, 可以通过map来对一列进行操作    \n",
    "\n",
    "df.pipe(lambda df_, x, y: df_[(df_.a >= x) & (df_.b <= y)], 2, 8)\n",
    "df.apply(fun)    # 自定义函数\n",
    "df['col3'] = df.apply(lambda x: x['col1'] + 2 * x['col2'], axis=1)\n",
    "df.applymap(lambda x: x\\*2)      # 所有元素的最大值\n",
    "df.team.map({'A':'一班', 'B':'二班', 'C':'三班', 'D':'四班'})     # 枚举替换\n",
    "\n",
    "将所有列聚合产生sum和min两行\n",
    "df.agg(['sum', 'min'])\n",
    "df.transform({'A':np.abs, 'B':lambda x: x + 1})\n",
    "\n",
    "#### 1.3.16　分组聚合\n",
    "参考：[DataFrame单列/多列进行运算](https://blog.csdn.net/zwhooo/article/details/79696558?)  \n",
    "df.groupby('team').describe()     # 描述性统计\n",
    "df.groupby('team').sum()     # 求和\n",
    "\n",
    "所有列使用一个计算方法\n",
    "df.groupby('team').aggregate(sum)\n",
    "df.groupby('team').agg(sum)\n",
    "grouped.agg(np.size)\n",
    "grouped['Q1'].agg(np.mean)\n",
    "\n",
    "多个计算方法\n",
    "grouped.agg([np.sum, np.mean, np.std])    # 所有列指定多个计算方法\n",
    "grouped['Q1'].agg([sum, np.mean, np.std])    # 指定列使用多个计算方法\n",
    "df.groupby('team').agg({'Q1': ['min', 'max'], 'Q2': 'sum'})   # 一个列使用多个计算方法  \n",
    "\n",
    "df.groupby('team').transform(np.std)    # 标准差\n",
    "df.groupby(['team']).filter(lambda x:(x.mean() >= 60).all())\n",
    "df.groupby('team').apply(lambda x:x.to_excel(f'{x.name}.xlsx'))   # 一个分组导出一个Excel文件\n",
    "df.groupby('team').pipe(lambda x: x.max() - x.min())   # 最大值和最小值之间的差值\n",
    "df.groupby('a').resample('M').sum()    # 按月 重采样\n",
    "\n",
    "数据分箱（分桶）\n",
    "pd.cut(df.Q1, bins=[0, 60, 100], labels=False)   # 不用区间，使用数字作为标签 (0, 1, 2, n)   \n",
    "\n",
    "pd.cut(df.Q1, bins=[0, 60, 100], labels=['不及格', '及格'])   # 指定标签名  \n",
    "pd.cut(df.Q1, bins=[0, 60, 100], include_lowest=True)    # 包含最低部分  \n",
    "pd.cut(df.Q1, bins=[0, 89, 100], right=False)   # 是否包含右边，闭区间，如：[89, 100)    \n",
    "\n",
    "pd.qcut(range(5), 4)\n",
    "pd.qcut(range(5), 4, labels=False)\n",
    "pd.qcut(range(5), 3, labels=['good', 'medium', 'bad'])   # 指定标签名\n",
    "\n",
    "#### 1.3.17 数据拼接\n",
    "　　参考：[全网最全 Python dataframe 数据合并方法汇总](https://blog.csdn.net/qq_34160248/article/details/124918723)  \n",
    "```python\n",
    "df.append(\n",
    "    other,\n",
    "    ignore_index: 'bool' = False,\n",
    "    verify_integrity: 'bool' = False,\n",
    "    sort: 'bool' = False,\n",
    ") -> 'DataFrame'\n",
    "```\n",
    "　　append主要用于追加数据，是比较简单直接的数据合并方式。  \n",
    "　　参数：  \n",
    "+ other: 用于追加的数据，可以是DataFrame或Series或组成的列表\n",
    "+ ignore_index: 是否保留原有的索引\n",
    "+ verify_integrity: 检测索引是否重复，如果为True则有重复索引会报错\n",
    "+ sort: 并集合并方式下，对columns排序\n",
    "\n",
    "df = df1.append(df2)   # 类似于list列表的append操作方式,但又有些不同    \n",
    "df1 = pd.DataFrame([[1, 2], [3, 4]])  \n",
    "df2 = pd.DataFrame([[5, 6], [7, 8]])  \n",
    "df = df1.append(df2, ignore_index=True)   # df1、df2不变，df为拼接结果（此为与list的不同）设置 ignore_index=True来对索引值进行重新排列    \n",
    "```python\n",
    "pd.concat(\n",
    "    objs: 'Iterable[NDFrame] | Mapping[Hashable, NDFrame]',\n",
    "    axis=0,\n",
    "    join='outer',\n",
    "    ignore_index: 'bool' = False,\n",
    "    keys=None,\n",
    "    levels=None,\n",
    "    names=None,\n",
    "    verify_integrity: 'bool' = False,\n",
    "    sort: 'bool' = False,\n",
    "    copy: 'bool' = True,\n",
    ") -> 'FrameOrSeriesUnion'\n",
    "```\n",
    "　　concat是pandas中专门用于数据连接合并的函数，功能非常强大，支持纵向合并和横向合并，默认情况下是纵向合并，具体可以通过参数进行设置。  \n",
    "参数：  \n",
    "+ objs: 用于连接的数据，可以是DataFrame或Series组成的列表\n",
    "+ axis=0 : 连接的方式，默认为0也就是纵向连接，可选 1 为横向连接\n",
    "+ join='outer'：合并方式，默认为 inner也就是交集，可选 outer 为并集\n",
    "+ ignore_index: 是否保留原有的索引，设置为True,相当于df.reset_index(drop=True)  \n",
    "+ keys=None：连接关系，使用传递的值作为一级索引\n",
    "+ levels=None：用于构造多级索引\n",
    "+ names=None：索引的名称\n",
    "+ verify_integrity: 检测索引是否重复，如果为True则有重复索引会报错\n",
    "+ sort: 并集合并方式下，对columns排序\n",
    "+ copy: 是否深度拷贝\n",
    "\n",
    "frames = [df1, df2]  \n",
    "df = pd.concat(frames, ignore_index=True)  \n",
    "df = pd.concat(frames, keys=['x', 'y'])  \n",
    "\n",
    "```python\n",
    "pd.merge(\n",
    "    left: 'DataFrame | Series',\n",
    "    right: 'DataFrame | Series',\n",
    "    how: 'str' = 'inner',\n",
    "    on: 'IndexLabel | None' = None,\n",
    "    left_on: 'IndexLabel | None' = None,\n",
    "    right_on: 'IndexLabel | None' = None,\n",
    "    left_index: 'bool' = False,\n",
    "    right_index: 'bool' = False,\n",
    "    sort: 'bool' = False,\n",
    "    suffixes: 'Suffixes' = ('_x', '_y'),\n",
    "    copy: 'bool' = True,\n",
    "    indicator: 'bool' = False,\n",
    "    validate: 'str | None' = None,\n",
    ") -> 'DataFrame'\n",
    "```\n",
    "　　merge函数方法类似SQL里的join，可以是pd.merge或者df.merge，区别就在于后者待合并的数据是  \n",
    "+ left: 用于连接的左侧数据\n",
    "+ right: 用于连接的右侧数据\n",
    "+ how: 数据连接方式，默认为 inner，可选outer、left和right\n",
    "+ on: 连接关键字段，左右侧数据中需要都存在，否则就用left_on和right_on\n",
    "+ left_on: 左侧数据用于连接的关键字段\n",
    "+ right_on: 右侧数据用于连接的关键字段\n",
    "+ left_index: True表示左侧索引为连接关键字段\n",
    "+ right_index: True表示右侧索引为连接关键字段\n",
    "+ suffixes: ‘Suffixes’ = (‘_x’, ‘_y’),可以自由指定，就是同列名合并后列名显示后缀\n",
    "+ indicator: 是否显示合并后某行数据的归属来源\n",
    "\n",
    "\n",
    "\n",
    "pd.merge(left, right, how='left', on=['key1', 'key2'])   # 以左表为基表  \n",
    "pd.merge_asof(left, right, on='a')  \n",
    "df1.combine_first(df2)   \n",
    "df.compare(df2)   \n",
    "pandas的merge函数只能同时合并三个dataframe，如果涉及到合并多个dataframe就比较麻烦。    \n",
    "\\# merge any number of dataframes  \n",
    "from functools import reduce  \n",
    "df_groups = [df2, group1, group2, group3, group4, group5, group6, group7, group8]  \n",
    "df_merged = reduce(lambda left, right: pd.merge(left, right, on=['title']), df_groups)   \n",
    "df_merged.head()   \n",
    " \n",
    "```python\n",
    "df.join(\n",
    "    other: 'FrameOrSeriesUnion',\n",
    "    on: 'IndexLabel | None' = None,\n",
    "    how: 'str' = 'left',\n",
    "    lsuffix: 'str' = '',\n",
    "    rsuffix: 'str' = '',\n",
    "    sort: 'bool' = False,\n",
    ") -> 'DataFrame'\n",
    "```\n",
    "参数：  \n",
    "+ other: 用于合并的右侧数据\n",
    "+ on: 连接关键字段，左右侧数据中需要都存在，否则就用left_on和right_on\n",
    "+ how: 数据连接方式，默认为 inner，可选outer、left和right\n",
    "+ lsuffix: 左侧同名列后缀\n",
    "+ rsuffix：右侧同名列后缀\n",
    "\n",
    "\n",
    "#### 1.3.18 数据透视\n",
    "df.pivot(index='foo', columns='bar', values='baz')   # 透视  \n",
    "\n",
    "#### 1.3.19 数据堆叠与反堆叠\n",
    "df_stack = df2.stack()    # 堆叠  \n",
    "df2 = df_stack.unstack()    # 反堆叠  \n",
    "\n",
    "#### 1.3.20 数据融合\n",
    "df3.melt(id_vars=['first', 'last'])  \n",
    "\n",
    "#### 1.3.21 数据转置\n",
    "df.T  \n",
    "df.transpose()  \n",
    "\n",
    "\n",
    "### 1.4 Pandas 时序数据处理\n",
    "　　参考：[时间字符串转时间戳_Pandas 时间序列 纵览与时间戳](https://blog.csdn.net/weixin_42600407/article/details/113369107)  \n",
    "       []()  \n",
    "\n",
    "　　Pandas 库中有四个与时间相关的概念：  \n",
    "+ 日期时间：日期时间表示特定日期和时间及其各自的时区。 它在 pandas 中的数据类型是 datetime64[ns] 或 datetime64[ns, tz]。  \n",
    "+ 时间增量：时间增量表示时间差异，它们可以是不同的单位。 示例：“天、小时、减号”等。换句话说，它们是日期时间的子类。  \n",
    "+ 时间跨度：时间跨度被称为固定周期内的相关频率。 时间跨度的数据类型是 period[freq]。  \n",
    "+ 日期偏移：日期偏移有助于从当前日期计算选定日期，日期偏移量在 pandas 中没有特定的数据类型。  \n",
    "+ Timedelta：在pandas中是一个表示两个datetime值之间的差(如日,秒和微妙)的类型,2个Datetime数据运算相减得出的结果就是一个Timedelta数据类型\n",
    "\n",
    "　　时间序列分析至关重要，因为它们可以帮助我们了解随着时间的推移影响趋势或系统模式的因素。 在数据可视化的帮助下，分析并做出后续决策。  \n",
    "　　相关函数：  \n",
    "pd.to_datetime() 把时间字符串(时间戳或日期)转换为时间格式，如：2022-08-25 12:07:17  \n",
    "pd.to_timedelta() 可以把时间差转换为timedelta格式  \n",
    "s.dt.total_seconds() 可以计算时间差的总秒数  \n",
    "\n",
    "指定开始时间、频率、周期数   \n",
    "pd.Series(range(3), index=pd.date_range('2000', freq='D', periods=3)  \n",
    "pd.Timestamp('2012-05-01')  \n",
    "pd.Timestamp(1513393355.5, unit='s')    # 单位为秒  \n",
    "pd.Timestamp(1513393355, unit='s', tz='Asia/Shanghai')    # 指定为北京时间  \n",
    "\n",
    "time.week    # 24 当年的第几周  \n",
    "time.weekofyear   # 24  同上  \n",
    "time.day    # 9 日  \n",
    "  \n",
    "s.astype('datetime64[ns]')  \n",
    "pd.to_datetime(['2005/11/23', '2010.12.31'])  # 把时间字符串转换为时间格式    \n",
    "\n",
    "pd.date_range(start='1/1/2018', periods=8)\n",
    "pd.bdate_range(start='1/1/2021', end='1/08/2021')\n",
    "\n",
    "two_business_days = 2 * pd.offsets.BDay()   # 下两个工作日\n",
    "ts.resample('5Min').mean()     # 平均\n",
    "\n",
    "方法： class pd.Timestamp(ts_input, freq=None, tz=None, unit=None,\n",
    "year=None, month=None, day=None, hour=None, minute=None,\n",
    "second=None, microsecond=None, nanosecond=None, tzinfo=None)#时间戳 ；替换datetime.datetime   \n",
    "\n",
    "参数：  \n",
    "ts_input：datetime-like,str,int,float#要转换为时间戳的值  \n",
    "freq： str,DateOffset  \n",
    "tz： str,pytz.timezone,dateutil.tz.tzfile或None#时间时区  \n",
    "unit : str#如ts_input为int或float,则用于转换的单位。该有效值为'D','h','m','s','ms','us'和'ns'  \n",
    "year, month, day :  int  \n",
    "hour, minute, second, microsecond : int, optional, default  0    \n",
    "nanosecond： int,optional,默认值为0    \n",
    "tzinfo： datetime.tzinfo,可选,默认无  \n",
    "\n",
    "构造方法：  \n",
    "```python\n",
    "# 实例1：日期时间的字符串\n",
    "pd.Timestamp('2019-01-01T12') # Timestamp('2019-01-01 12:00:00')\n",
    "pd.Timestamp('2019-01-16 20:22:2')# Timestamp('2019-01-16 20:22:02')\n",
    " \n",
    "# 实例2：以秒为单位转换表示Unix纪元的浮点数\n",
    "pd.Timestamp(1513393355.5, unit='s')# Timestamp('2019-12-16 03:02:35.500000')\n",
    "pd.Timestamp(1513393355, unit='s', tz='US/Pacific')#特定时区\n",
    "# Timestamp('2019-12-15 19:02:35-0800', tz='US/Pacific')\n",
    " \n",
    "#实例3：模仿datetime.datetime：通过位置或关键字,不能两者混合\n",
    "pd.Timestamp(2019, 1, 16, 20,26,30) #Timestamp('2019-01-16 20:26:30')\n",
    " \n",
    "pd.Timestamp(year=2019, month=1, day=16, hour=20,\n",
    "minute=28, second=30, microsecond=30)#Timestamp('2019-01-16 20:28:30.000030')\n",
    "\n",
    "## 属性\n",
    "d=pd.Timestamp.now()\n",
    "d=pd.Timestamp(d,tz='Asia/Shanghai')\n",
    "d# Timestamp('2019-01-16 20:41:19.035134+0800', tz='Asia/Shanghai')\n",
    " \n",
    "d.tz # <DstTzInfo 'Asia/Shanghai' CST+8:00:00 STD>\n",
    "d.tzinfo# <DstTzInfo 'Asia/Shanghai' CST+8:00:00 STD>\n",
    " \n",
    "d.day_name#替代d.weekday_name\n",
    "# <bound method Timestamp.day_name of Timestamp('2019-01-16 20:41:19.035134+0800', tz='Asia/Shanghai')>\n",
    " \n",
    "d.asm8# numpy.datetime64('2019-01-16T12:41:19.035134000')\n",
    " \n",
    "d.weekofyear # 3\n",
    "d.dayofweek # 2周三\n",
    "d.dayofyear # 16\n",
    "d.days_in_month# 31\n",
    "d.daysinmonth # 31\n",
    " \n",
    "d.day # 16\n",
    "d.microsecond # 35134\n",
    "d.minute # 41\n",
    "d.month # 1\n",
    "d.nanosecond # 0\n",
    "d.quarter# 1\n",
    "d.second# 19\n",
    "d.week # 3\n",
    "d.year # 2019\n",
    "d.hour # 20\n",
    " \n",
    "d.fold# 0\n",
    "d.freq\n",
    "d.freqstr\n",
    " \n",
    "d.is_leap_year # False\n",
    "d.is_month_end # False\n",
    "d.is_month_start # False\n",
    "d.is_quarter_end # False\n",
    "d.is_quarter_start# False\n",
    "d.is_year_end # False\n",
    "d.is_year_start # False\n",
    " \n",
    "d.value# 1547642479035134000\n",
    "\n",
    "\n",
    "## 方法：\n",
    "d=pd.Timestamp.now()\n",
    "d=pd.Timestamp(d,tz='Asia/Shanghai')\n",
    " \n",
    "d # Timestamp('2019-01-16 20:41:19.035134+0800', tz='Asia/Shanghai')\n",
    " \n",
    "d.astimezone('UTC') # Timestamp('2019-01-16 12:41:19.035134+0000', tz='UTC')\n",
    "d.ceil(pd.tseries.offsets.Day(2))# Timestamp('2019-01-18 00:00:00+0800', tz='Asia/Shanghai')\n",
    " \n",
    "d.ctime() # 'Wed Jan 16 20:41:19 2019'\n",
    "d.day_name() # 'Wednesday'\n",
    "d.dst() # datetime.timedelta(0)\n",
    "d.floor('2D') # Timestamp('2019-01-16 00:00:00+0800', tz='Asia/Shanghai')不太明白？\n",
    " \n",
    "d.timestamp() # 1547642479.035134\n",
    "d.fromtimestamp(1547642479.035134)# Timestamp('2019-01-16 20:41:19.035134')\n",
    "d.utcfromtimestamp(d.timestamp()) # Timestamp('2019-01-16 12:41:19.035134')\n",
    " \n",
    "d.toordinal() # 737075\n",
    "d.fromordinal(d.toordinal())# Timestamp('2019-01-16 00:00:00')\n",
    " \n",
    "d.isocalendar()# (2019, 3, 3)\n",
    "d.round('D') # Timestamp('2019-01-17 00:00:00+0800', tz='Asia/Shanghai')\n",
    " \n",
    "d.timetuple # <function Timestamp.timetuple>\n",
    "d.timetuple()# time.struct_time(tm_year=2019, tm_mon=1, tm_mday=16, tm_hour=20, tm_min=41, tm_sec=19, tm_wday=2, tm_yday=16, tm_isdst=0)\n",
    " \n",
    "d.to_datetime64()# numpy.datetime64('2019-01-16T12:41:19.035134000')\n",
    " \n",
    "d.to_julian_date()# 2458500.3620258695\n",
    "d.tzname() # 'CST'\n",
    " \n",
    "d.isoformat()# '2019-01-16T20:41:19.035134+08:00'\n",
    "\n",
    "\n",
    "## 实例：Series,DataFrame.dt访问时间戳属性方法\n",
    "rng = pd.date_range('2019-01-01', '2019-01-03',freq='1D') #'2h30min' 'WOM-3FRI'每月第3个周五\n",
    "s = pd.Series(pd.date_range('2019-01-01', '2019-01-03'))\n",
    " \n",
    "s\n",
    "'''''''''\n",
    "0 2019-01-01\n",
    "1 2019-01-02\n",
    "2 2019-01-03\n",
    "dtype: datetime64[ns]\n",
    "'''\n",
    "s.dt.day_name()\n",
    "'''''''''\n",
    "0 Tuesday\n",
    "1 Wednesday\n",
    "2 Thursday\n",
    "dtype: object\n",
    "'''\n",
    "s.dt.day\n",
    "'''''''''\n",
    "0 1\n",
    "1 2\n",
    "2 3\n",
    "dtype: int64\n",
    "''' \n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### 1.5 Pandas 文本处理\n",
    "pd.Series(['a', 'b', 'c'], dtype='string')\n",
    "pd.Series(['a', 'b', 'c'], dtype=pd.StringDtype())\n",
    "\n",
    "pd.StringDtype(storage='pyarrow')     # storage 默认为python,指定 pyarrow\n",
    "pd.Series(['abc', None, 'def'], dtype='string[pyarrow]')  \n",
    "s2.str.split('\\_')  \n",
    "s2.str.split('\\_', expand=True)\n",
    "\n",
    "s.str.replace('￥', '')  \n",
    "s.str.lower()   # 转为小写\n",
    "s.str.upper()   # 转为大写\n",
    "s.str.title()   # 标题格式，每个单词大写\n",
    "s.str.capitalize()   # 首字母大写\n",
    "s.str.swapcase()    # 大小写互换\n",
    "\n",
    "### 1.6 窗口计算\n",
    "ser.rolling(window=5, win_type='boxcar').mean()    # 移动窗口\n",
    "ser.rolling(window=5).mean()  \n",
    "\n",
    "ser.rolling(window=5, win_type='triang').mean()  \n",
    "ser.rolling(window=5, win_type='gaussian').mean(std=0.1)  \n",
    "\n",
    "df.expanding(min_periods=1).mean()     # 扩展窗口\n",
    "\n",
    "### 1.7 样式处理\n",
    "df.style.highlight_null(null_color='blue')\n",
    "df.head().style.highlight_max()    # 最大值高亮。默认黄色\n",
    "df.head().style.highlight_min()    # 最小值高亮\n",
    "df.style.highlight_between(left=60, right=100, subset=['Q4'])  # Q4列的60~100高亮  \n",
    "df.style.highlight_quantile(axis=1, q_left=0.8, color='#fffd75')   \n",
    "df.style.text_gradient(axis=0)  \n",
    "df.style.background_gradient(subset=['Q1'], cmap='BuGn')  \n",
    "df.style.bar(subset=['Q1'])   \n",
    "df.style.format(\"{:.2%}\")   # 百分号，类似 29.57%\n",
    "常用格式\n",
    "{'a': '￥{0:,.0f}',    # 货币符号\n",
    " 'b': '{:%Y-%m}',     # 年月\n",
    " 'c': '{:.2%}',     # 百分号\n",
    " 'd': '{:,f}',      # 千分位\n",
    " 'e': str.upper     # 大写\n",
    "}\n",
    "\n",
    "### 1.8 可视化\n",
    "df.plot.line()    # 折线的全写方式  \n",
    "df.plot.bar()     # 柱状图  \n",
    "df.plot.barh()    # 横向柱状图（条形图）    \n",
    "df.plot.hist()    # 直方图    \n",
    "df.plot.box()     # 箱型图  \n",
    "df.plot.kde()     # 核密度估计图     \n",
    "df.plot.density()   # 同  df.plot.kde()    \n",
    "df.plot.area()    # 面积图    \n",
    "df.plot.pie()     # 饼图    \n",
    "df.plot.scatter()   # 散点图   \n",
    "df.plot.hexbin()    # 六边形箱体图，或 六边形图   \n",
    "plt.show()     # 输出图形  \n",
    "  \n",
    "方法：     \n",
    "DataFrame.plot(x=None, y=None, kind='line', ax=None, subplots=False, sharex=None, sharey=False, layout=None, figsize=None, use_index=True, title=None, grid=None, legend=True, style=None, logx=False, logy=False, loglog=False, xticks=None, yticks=None, xlim=None, ylim=None, rot=None, fontsize=None, colormap=None, position=0.5, table=False, yerr=None, xerr=None, stacked=True/False, sort_columns=False, secondary_y=False, mark_right=True, \\*\\*kwds)   \n",
    "参数：  \n",
    "x : 标签 或者位置参数(横向标记位置)，默认None；  \n",
    "y : 标签 或者位置参数(纵向标记位置)，默认None；  \n",
    "kind : 绘制类型，字符串类型  \n",
    "+ ‘line’ : line plot (default)     # 折线图\n",
    "+ ‘bar’  : vertical bar plot      # 条形图\n",
    "+ ‘barh’ : horizontal bar plot     # 横向条形图\n",
    "+ ‘hist’ : histogram           # 柱状图\n",
    "+ ‘box’  : boxplot             #箱线图\n",
    "+ ‘kde’  : Kernel Density Estimation plot #密度估计图，主要对柱状图添加Kernel 概率密度线\n",
    "+ ‘density’ : same as ‘kde’\n",
    "+ ‘area’ : area plot            #面积区域图\n",
    "+ ‘pie’ : pie plot             #饼图\n",
    "+ ‘scatter’ : scatter plot        #散点图  需要传入columns方向的索引\n",
    "+ ‘hexbin’ : hexbin plot         #具有六边形单元的二维直方图 蜂巢图模式\n",
    "ax：轴对象，默认None(子图,如果没有设置，则使用当前matplotlib subplot**)   \n",
    "subplots : boolean, default False   # 图片中是否有子图  \n",
    "sharex：bool, default True if ax is None else False。ax存在则为True,否则False。如果subplots=True, 如果有子图，子图共x轴刻度。   \n",
    "sharey：bool, 默认 False。如果 subplots=True, 子图共y轴刻度，标签。  　\n",
    "layout：元组形式, optional。(rows, columns) 子图的行列布局  　　　\n",
    "figsize：图片大小，元组形式，figsize=(8,6)\n",
    "use_index：bool, 默认 True 是否使用索引作为x轴的刻度   \n",
    "title： 图片标题，字符串或者列表形式 。传入字符串，在图形顶部打印该字符串；传递了一个列表且子图为真，则每个子图上边打印列表相应的标题  \n",
    "grid : boolean, default None (matlab style default)   # 图片是否有网格  \n",
    "legend : False/True/’reverse’  # 子图的图例，添加一个subplot图例(默认为True)  \n",
    "style：对每列折线图设置线的类型，列表或者字典形式  \n",
    "logx : boolean, default False    # 设置x轴刻度是否取对数  \n",
    "logy : boolean, default False    # 设置y轴刻度是否取对数  \n",
    "loglog : boolean, default False   # 同时设置x，y轴刻度是否取对数   \n",
    "xticks : sequence    # 设置x轴刻度值，序列形式（比如列表）  \n",
    "yticks : sequence    # 设置y轴刻度值，序列形式（比如列表)  \n",
    "rot: int, default None   # 设置轴标签（轴刻度）的显示旋转度数  \n",
    "fontsize : int, default None   # 设置轴刻度的字体大小   \n",
    "colormap : str or matplotlib colormap object, default None     # 设置图的区域颜色    \n",
    "colorbar : boolean, optional   # 图片柱子 If True, plot colorbar (only relevant for ‘scatter’ and ‘hexbin’ plots)       \n",
    "position : float   # 取值范围[0,1],默认为0.5表示中间对齐,设置图的区域颜色   \n",
    "table : boolean, Series or DataFrame, default False  # 如果为正，则选择DataFrame类型的数据并且转换匹配matplotlib的布局。  \n",
    "yerr : DataFrame, Series, array-like, dict and str. See Plotting with Error Bars for detail.   \n",
    "xerr : same types as yerr.   \n",
    "stacked : boolean, default False in line and bar plots, and True in area plot. If True, create stacked plot.\n",
    "sort_columns : boolean, default False       # 以字母表顺序绘制各列，默认使用前列顺序  \n",
    "secondary_y : boolean or sequence, default False    # 设置第二个y轴（右y轴）     \n",
    "mark_right : 默认为True,在使用第二个Y轴时在Y轴上的标签   \n",
    "kwds : keywords # 关键词\n",
    "Options to pass to matplotlib plotting method\n",
    "\n",
    "### 1.9 缺失值、空值、异常值\n",
    "df.isnull().sum()     # 检查缺失值    \n",
    "df.info()    # 查看数据信息 - 可推断出缺失值数量    \n",
    "df.fillna('\\*')     # 缺失值处理：将缺失值替换为“\\*”    \n",
    "df['Q1'] = df['Q1'].fillno('\\*')    # 仅处理某一列的缺失值     \n",
    "df['Q1'] = df['Q1'].fillno(df['Q1'].mean())    # 仅处理某一列的缺失值:替换为平均值      \n",
    "df['Q1'] = df['Q1'].fillno(df['Q1'].interpolate())    # 仅处理某一列的缺失值：使用插值法 - 取数据缺失值上下的数字的平均值    \n",
    "df = df.fillna(axis=1, method='ffill')     # 使用横向/纵向的前面的值替换缺失值  axis 1 纵向  0  横向   \n",
    "df = df.dropna()      # 删除缺失值（删所有缺失值所在行）   \n",
    "df = df.dropna(subset=['Q1'])     # 删除Q1列缺失值所在行   \n",
    "1.3.10　数据转换\n",
    "1.3.11　增加列\n",
    "1.3.12　统计分析\n",
    "1.3.13　绘图\n",
    "1.3.14　导出\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 二、Pandas数据结构\n",
    "2.1　数据结构概述25\n",
    "2.1.1　什么是数据25\n",
    "2.1.2　什么是数据结构26\n",
    "2.1.3　小结26\n",
    "2.2　Python的数据结构26\n",
    "2.2.1　数字27\n",
    "2.2.2　字符串27\n",
    "2.2.3　布尔型28\n",
    "2.2.4　列表29\n",
    "2.2.5　元组30\n",
    "2.2.6　字典30\n",
    "2.2.7　集合31\n",
    "2.2.8　小结32\n",
    "2.3　NumPy32\n",
    "2.3.1　NumPy简介33\n",
    "2.3.2　数据结构33\n",
    "2.3.3　创建数据34\n",
    "2.3.4　数据类型34\n",
    "2.3.5　数组信息35\n",
    "2.3.6　统计计算35\n",
    "2.3.7　小结35\n",
    "2.4　Pandas的数据结构35\n",
    "### 2.4.1　Series\n",
    "构造Series: s = pd.Series(['a', 'b', 'c', 'd', 'e'])\n",
    "　　可传入：列表和元组\n",
    "  　　　　　字典：键为索引，值为Series值。\n",
    "       　　ndarray\n",
    "         　标量\n",
    "### 2.4.2　DataFrame\n",
    "构造DataFrame: df = pd.DataFrame({'国家':['中国', '美国', '日本'],\n",
    "                                  '地区':['亚洲', '北美', '亚洲'],\n",
    "                                  '人口':[13.97, 3.28, 1.26],\n",
    "                                  'GDP':[14.34, 21.43, 5.08]\n",
    "                                })\n",
    "可传入：字典（值为Series的可构造类型）\n",
    "　　　　Series\n",
    "#### 2.4.2.2、从字典构建DataFrame\n",
    "```python\n",
    "pd.DataFrame.from_dict(data, orient=‘columns’, dtype=None, columns=None)\n",
    "```\n",
    "参数名：类型\n",
    "data：dict Of the form {field : array-like} or {field : dict}.\n",
    "orient：{‘columns’, ‘index’, ‘tight’}, default ‘columns’用于数据的指向.如果orient='columns'，表示将字典keys作为列属性名；如果orient='index'，表示将字典的keys作为索引名,values作为属性值。If‘tight’,assume a dict with keys [‘index’,‘columns’,‘data’,‘index_names’,‘column_names’].(具体见示例)  \n",
    "dtype：dtype, default None 强制数据类型转换\n",
    "columns：list, default None  当orient='index'，能够指定columns的名称\n",
    "返回值：DataFrame\n",
    "\n",
    "pd.DataFrame.from_records()\n",
    "pd.json_normalize()\n",
    "\n",
    "\n",
    "2.4.3　索引37\n",
    "2.4.4　小结38\n",
    "2.5　Pandas生成数据38\n",
    "2.5.1　导入Pandas38\n",
    "2.5.2　创建数据38\n",
    "2.5.3　生成Series40\n",
    "2.5.4　生成DataFrame41\n",
    "2.5.5　小结43\n",
    "2.6　Pandas的数据类型43\n",
    "2.6.1　数据类型查看43\n",
    "2.6.2　常见数据类型44\n",
    "2.6.3　数据检测44\n",
    "2.6.4　小结45\n",
    "2.7　本章小结45\n",
    "\n",
    "## 三、Pandas基础操作\n",
    "4.1　索引操作66\n",
    "4.1.1　认识索引66\n",
    "4.1.2　建立索引67\n",
    "4.1.3　重置索引68\n",
    "4.1.4　索引类型68\n",
    "4.1.5　索引对象69\n",
    "4.1.6　索引的属性70\n",
    "4.1.7　索引的操作70\n",
    "4.1.8　索引重命名72\n",
    "4.1.9　修改索引内容72\n",
    "4.1.10　小结73\n",
    "4.2　数据的信息73\n",
    "4.2.1　查看样本73\n",
    "4.2.2　数据形状74\n",
    "4.2.3　基础信息74\n",
    "4.2.4　数据类型74\n",
    "4.2.5　行列索引内容75\n",
    "4.2.6　其他信息75\n",
    "4.2.7　小结75\n",
    "4.3　统计计算76\n",
    "4.3.1　描述统计76\n",
    "4.3.2　数学统计77\n",
    "4.3.3　统计函数78\n",
    "4.3.4　非统计计算79\n",
    "4.3.5　小结80\n",
    "4.4　位置计算80\n",
    "4.4.1　位置差值diff()80\n",
    "4.4.2　位置移动shift()81\n",
    "4.4.3　位置序号rank()81\n",
    "4.4.4　小结82\n",
    "4.5　数据选择82\n",
    "4.5.1　选择列83\n",
    "4.5.2　切片[]83\n",
    "4.5.3　按轴标签.loc84\n",
    "4.5.4　按数字索引.iloc86\n",
    "4.5.5　取具体值.at/.iat86\n",
    "4.5.6　获取数据.get86\n",
    "4.5.7　数据截取.truncate87\n",
    "4.5.8　索引选择器87\n",
    "4.5.9　小结87\n",
    "4.6　本章小结88\n",
    "\n",
    "\n",
    "## 四、Pandas数据读取输出\n",
    "### 4.1　数据读取\n",
    "#### 4.1.1　CSV文件\n",
    "　　[python pandas导入csv数据时如何去除默认索引？](https://www.zhihu.com/question/62754199/answer/2209381497)   \n",
    "```python\n",
    "pd.read_csv(\n",
    "    filepath_or_buffer: FilePath | ReadCsvBuffer[bytes] | ReadCsvBuffer[str],\n",
    "    sep=lib.no_default,     # 分隔符，通常为英文逗号，某些地方用分号或\\t  \n",
    "    delimiter=None,\n",
    "    # Column and Index Locations and Names\n",
    "    header=\"infer\",\n",
    "    names=lib.no_default,\n",
    "    index_col=None,\n",
    "    usecols=None,\n",
    "    squeeze=None,\n",
    "    prefix=lib.no_default,\n",
    "    mangle_dupe_cols=True,\n",
    "    # General Parsing Configuration\n",
    "    dtype: DtypeArg | None = None,\n",
    "    engine: CSVEngine | None = None,\n",
    "    converters=None,\n",
    "    true_values=None,\n",
    "    false_values=None,\n",
    "    skipinitialspace=False,\n",
    "    skiprows=None,\n",
    "    skipfooter=0,\n",
    "    nrows=None,\n",
    "    # NA and Missing Data Handling\n",
    "    na_values=None,\n",
    "    keep_default_na=True,\n",
    "    na_filter=True,\n",
    "    verbose=False,\n",
    "    skip_blank_lines=True,\n",
    "    # Datetime Handling\n",
    "    parse_dates=None,\n",
    "    infer_datetime_format=False,\n",
    "    keep_date_col=False,\n",
    "    date_parser=None,\n",
    "    dayfirst=False,\n",
    "    cache_dates=True,\n",
    "    # Iteration\n",
    "    iterator=False,\n",
    "    chunksize=None,\n",
    "    # Quoting, Compression, and File Format\n",
    "    compression: CompressionOptions = \"infer\",\n",
    "    thousands=None,\n",
    "    decimal: str = \".\",\n",
    "    lineterminator=None,\n",
    "    quotechar='\"',\n",
    "    quoting=csv.QUOTE_MINIMAL,\n",
    "    doublequote=True,\n",
    "    escapechar=None,\n",
    "    comment=None,\n",
    "    encoding=None,     # 读取的csv文件的编码，如：utf-8、gb2312\n",
    "    encoding_errors: str | None = \"strict\",\n",
    "    dialect=None,\n",
    "    # Error Handling\n",
    "    error_bad_lines=None,\n",
    "    warn_bad_lines=None,\n",
    "    # TODO(2.0): set on_bad_lines to \"error\".\n",
    "    # See _refine_defaults_read comment for why we do this.\n",
    "    on_bad_lines=None,\n",
    "    # Internal\n",
    "    delim_whitespace=False,\n",
    "    low_memory=_c_parser_defaults[\"low_memory\"],\n",
    "    memory_map=False,\n",
    "    float_precision=None,\n",
    "    storage_options: StorageOptions = None,\n",
    ")\n",
    "```\n",
    "\n",
    "　　参考：[DtypeWarning](https://blog.csdn.net/weixin_38987362/article/details/81325671)  \n",
    "df = pd.read_csv('data.csv')\n",
    "df = pd.read_csv('https://www.gairuo.com/file/data/dataset/GDP-China.csv')    \n",
    "\n",
    "df.to_dict('df.csv')       # 将df对象存储到csv文件\n",
    "df.to_dict(orient='records')  # 将df对象转化为字典结构，方便处理\n",
    "\n",
    "#### 4.1.2　Excel文件\n",
    "df = pd.read_excel('data.xlsx')\n",
    "\n",
    "#### 4.1.3　JSON文件\n",
    "df = pd.read_json('data.json')\n",
    "\n",
    "#### 4.1.4　HTML\n",
    "df = pd.read_html(url, attrs={'id':'table'})\n",
    "\n",
    "#### 4.1.5　剪贴板\n",
    "df = pd.read_clipboard()\n",
    "\n",
    "#### 4.1.6　SQL\n",
    "df = pd.read_sql_table('data', coon)\n",
    "\n",
    "#### 4.1.7 XML文件\n",
    "df = pd.read_xml(file_path, xpath=\"//book\\[year=2005\\]\")\n",
    "\n",
    "#### 4.1.7　小结52\n",
    "3.2　读取CSV52\n",
    "3.2.1　语法52\n",
    "3.2.2　数据内容53\n",
    "3.2.3　分隔符53\n",
    "3.2.4　表头54\n",
    "3.2.5　列名54\n",
    "3.2.6　索引54\n",
    "3.2.7　使用部分列54\n",
    "3.2.8　返回序列55\n",
    "3.2.9　表头前缀55\n",
    "3.2.10　处理重复列名55\n",
    "3.2.11　数据类型55\n",
    "3.2.12　引擎55\n",
    "3.2.13　列数据处理56\n",
    "3.2.14　真假值转换56\n",
    "3.2.15　跳过指定行56\n",
    "3.2.16　读取指定行57\n",
    "3.2.17　空值替换57\n",
    "3.2.18　保留默认空值57\n",
    "3.2.19　日期时间解析58\n",
    "3.2.20　文件处理59\n",
    "3.2.21　符号60\n",
    "3.2.22　小结61\n",
    "3.3　读取Excel61\n",
    "3.3.1　语法61\n",
    "3.3.2　文件内容62\n",
    "3.3.3　表格62\n",
    "3.3.4　表头62\n",
    "3.3.5　列名62\n",
    "3.3.6　其他62\n",
    "3.3.7　小结63\n",
    "3.4　数据输出63\n",
    "3.4.1　CSV63\n",
    "3.4.2　Excel63\n",
    "3.4.3　HTML64\n",
    "3.4.4　数据库（SQL）64\n",
    "3.4.5　Markdown65\n",
    "3.4.6　小结65\n",
    "3.5　本章小结65\n",
    "\n",
    "## 五、Pandas高级操作\n",
    "5.1　复杂查询89\n",
    "5.1.1　逻辑运算89\n",
    "5.1.2　逻辑筛选数据91\n",
    "5.1.3　函数筛选92\n",
    "5.1.4　比较函数92\n",
    "5.1.5　查询df.query()93\n",
    "5.1.6　筛选df.filter()93\n",
    "5.1.7　按数据类型查询93\n",
    "## 六、Pandas数据处理\n",
    "\n",
    "\n",
    "## 二、Series 对象\n",
    "### 2.1、创建Series\n",
    "\n",
    "### 2.2、Series 切片与索引\n",
    "#### 2.2.1 切片索引\n",
    "　　可通过 索引（[start, end, step]）、位置、位置列表 来取   \n",
    "　　Boolean 索引，如：s = pd.Series(range(7))   s[s>4]表示取s中大于4的值\n",
    "#### 2.2.2、获取索引 值\n",
    "　　s.index   s.values   属性\n",
    "　　Series本质上市有两个数组构成：一个数组构成对象的键（index - 索引），一个数组构成对象的值（values）。  \n",
    "  \n",
    "## 三、DataFrame 对象\n",
    "\n",
    "### 2.1、创建 DataFrame\n",
    "\n",
    "### 2.2、切片索引\n",
    "\n",
    "#### 2.2.2、loc[] 标签索引取值\n",
    "#### 2.2.3、iloc[] 位置索引取值\n",
    "\n",
    "### 2.3、\n",
    "\n",
    "\n",
    "### 2.4、\n",
    "\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

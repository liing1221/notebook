{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 机器学习 sklearn4——[特征选择](https://blog.csdn.net/u010089444/article/details/70053104)、[特征工程](https://blog.csdn.net/weiyongle1996/article/details/79137078)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**特征选择**<br>\n",
    "　　数据预处理完成后，接下来需要从给定的特征集合中筛选出对当前学习任务有用的特征，这个过程称为特征选择（feature selection）。通常来说，从两个方面来选择特征：<br>\n",
    "　　1、特征是否发散：如果一个特征不发散，例如方差接近于0，也就是说样本在这个特征上基本上没有差异，这个特征对于样本的区分并没有什么用。<br>\n",
    "　　2、特征与目标的相关性：这点比较显见，与目标相关性高的特征，应当优选选择。<br>\n",
    "常见的特征选择方法可分为三类：过滤法（Filter）、包裹法（Wrapper）、嵌入法（Embedding）<br>\n",
    "　　1、过滤法：按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。<br>\n",
    "　　2、包裹法：包裹式特征选择直接把最终要使用的学习器性能作为特征子集的评价标准。<br>\n",
    "　　3、嵌入法：将特征选择过程和机器训练过程融合为一体。两者在同一优化过程中完成，即在学习器训练过程中自动进行了特征选择。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 过滤法（filter）<br>\n",
    "**方差过滤法:**<br>\n",
    "方差过滤法需要计算每个特征的方差，然后根据阈值删除取值小于阈值的特征。例如，假设某特征的取值为0和1，且训练集中有90%以上的数据在该特征的取值为1，那么可认为该特征对于区分不同数据的作用不大。方差过滤法只能用于筛选离散的特征，如果特征的取值是连续的，就需要将连续值离散化之后才能用。使用feature_selection库的VarianceThreshold类来选择特征的代码如下：<br>\n",
    "from sklearn.feature_selection import VarianceThreshold<br>\n",
    "\n",
    "方差选择法，返回值为特征选择后的数据<br>\n",
    "参数threshold为方差的阈值<br>\n",
    "VarianceThreshold(threshold=3).fit_transform(iris.data)<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
